# daemon off;
worker_processes 2;             # Rule of thumb: one per CPU (auto)
                                # Align with k8s spec.resources.limit.cpu
error_log  /proc/self/fd/2 warn;
pid        /var/lib/nginx/nginx.pid;

events {
    worker_connections  1024;   # Max concurrent connections per worker
    multi_accept on;            # Allow workers to accept all pending connections at once, rather than one by one
    use epoll;                  # Linux optimization
}

http {
    include /etc/nginx/mime.types;

    # Extract the left-most IP from X-Forwarded-For header (for rate limiting etc.)
    # Rely on Ingress to "trust" proxies
    map $http_x_forwarded_for $real_client_ip {

        # ^         Start of string
        # ()        Capture group
        #   [^,\s]  Any non-whitespace, non-comma character
        #   +       One or more such characters
        # $1        Return the first result

        ~^([^,\s]+) $1;
        default "";
    }

    # Nginx duplicates the X-Request-Id header, so extract the first value
    map $http_x_request_id $request_id_header {

        # ^         Start of string
        # ()        Capture group
        #   [^,\s]  Any non-whitespace, non-comma character
        #   +       One or more such characters
        # $1        Return the first result

        ~^([^,]+) $1;
        default "";
    }

    log_format debug '$request_id_header $time_iso8601 $request $status $upstream_status '

                # Client/Nginx Connection
                'c=$connection '                    # Connection serial number
                'cr=$connection_requests '          # Number of requests made on this connection
                'ct=$connection_time '              # Connection time (seconds)

                # Times
                'rt=$request_time '                 # From first read to last byte sent
                'uct=$upstream_connect_time '
                'uht=$upstream_header_time '        # From first byte sent to PHP-FPM till first response header byte received by Nginx
                'urt=$upstream_response_time '      # From first byte sent to PHP-FPM till last response byte received by Nginx

                # Request size
                'rl=$request_length '               # Request line + headers + body
                'cl=$http_content_length '          # Body (from Content-Length header)
                'ubs=$upstream_bytes_sent '         # FastCGI params + request body

                # Response size
                'url=$upstream_response_length '    # FastCGI params + response body
                'bs=$bytes_sent '                   # Response bytes sent (status line + headers + body + HTTP/2 Frame Overhead)
                'bbs=$body_bytes_sent '             # Response body bytes sent
                'scl=$sent_http_content_length '    # Response body (from Content-Length header)

                '$http_referer "$http_user_agent" '
                ;
    access_log  /proc/self/fd/1 debug;

    # ephemeral storage
    client_body_temp_path /var/lib/nginx/tmp/client;
    fastcgi_temp_path     /var/lib/nginx/tmp/fastcgi;
    proxy_temp_path       /var/lib/nginx/tmp/proxy;
    scgi_temp_path        /var/lib/nginx/tmp/scgi;
    uwsgi_temp_path       /var/lib/nginx/tmp/uwsgi;

    # persistent storage
    # fastcgi_cache_path    /var/lib/nginx/cache/fastcgi levels=1:2 keys_zone=fastcgi_cache:10m inactive=60m;
    # proxy_cache_path      /var/lib/nginx/cache/proxy levels=1:2 keys_zone=proxy_cache:10m inactive=60m;

    # Rate Limiting
    limit_req_zone $real_client_ip zone=req_api:10m rate=5r/s;      # Rate limiting                     503 Service Unavailable
                                                                    # 5 request/second --> 1 request allowed every 200ms (per IP)
                                                                    # 10MB / ~64b ≈ ~160,000 records (IP, last access time, excess counters, rate buckets)
                                                                    # burst: queue size for excess requests
                                                                    # nodelay: process queue instantly (but still fill the queue for the relevant time)

    limit_conn_zone $real_client_ip zone=conn_api:124k;             # Limit concurrent connections      503 Service Unavailable
                                                                    # 1MB / 64b ≈ 16,384 concurrent IPs / mb
                                                                    # Required memory = Max concurrent connections * 64b
                                                                    # = worker_processes * worker_connections * 64b
                                                                    # = 2 * 1024 * 64b = 124kb

    # Performance optimizations
    sendfile on;                        # Lets Nginx send static files directly from disk
    tcp_nopush on;                      # Send headers in one piece
    tcp_nodelay on;                     # Don't buffer data-sends
    server_tokens off;                  # Prevents Nginx revealing its version in error pages and `Server:` headers

    # Uploads
    client_max_body_size 1m;            # >= php:post_max_size, >= php:upload_max_filesize          413 Request Entity Too Large    

    # Timeouts
    client_header_timeout 10s;          # Timeout for client to send request line & headers         408 Request Timeout             client timed out
    client_body_timeout 10s;            # Timeout for client to send body (incl. file upload)       408 Request Timeout             client timed out
    reset_timedout_connection on;       # Sends a TCP RST (reset) packet on `client_header_timeout` / `client_body_timeout`
                                        # Free up memory, file descriptors
    fastcgi_connect_timeout 3s;         # Timeout to establish connection to PHP-FPM                502 Bad Gateway                 upstream timed out
    fastcgi_send_timeout 10s;           # Timeout for sending request to PHP-FPM                    504 Gateway Timeout             upstream timed out      (i.e. large request, or PHP-FPM overwhelmed)
    fastcgi_read_timeout 35s;           # Timeout for reading response from PHP-FPM                 504 Gateway Timeout             upstream timed out (110: Operation timed out) while reading response header from upstream
                                        # >= php-fpm:request_terminate_timeout                      If PHP times out first: 500
                                        # >= php:max_execution_time                                 If PHP times out first: 500
    send_timeout 30s;                   # Timeout for sending response to client                    504 Gateway Timeout             client was aborted

    # Client -> Nginx
    client_header_buffer_size 1k;       # Memory for request line & headers. If insufficient, use `large_client_header_buffers` instead
    large_client_header_buffers 4 4k;   # Larger memory for request line & headers. If exceeded:    400 Bad Request                 client sent too large header   or   header too large
    client_body_buffer_size 128k;       # Memory for request body. Excess to `client_body_temp_path`

    # Nginx -> PHP-FPM
    fastcgi_request_buffering on;       # Read entire request before sending to PHP-FPM
                                        # If off, $_POST, $_FILES will be empty or incomplete; must read from php://input

    # PHP-FPM -> Nginx
    fastcgi_buffering on;               # Read entire response before sending to client
                                        # Align with php:output_buffering, php:implicit_flush
    fastcgi_buffer_size 32k;            # Memory for response first part. If headers exceed:        502 Bad Gateway                 upstream sent too big header while reading response header from upstream   or   upstream sent invalid header
    fastcgi_buffers 8 32k;              # Memory for remaining (non-header) response.
                                        # Excess to `fastcgi_temp_path`
    fastcgi_max_temp_file_size 100m;    # When `fastcgi_buffers` exceed, maximum file size.         502 Bad Gateway                 temp file write error
    fastcgi_temp_file_write_size 32k;   # When `fastcgi_buffers` exceed, how much to write to disk at once (write chunking)
                                        # >= max(fastcgi_buffer_size, fastcgi_buffers)
    fastcgi_busy_buffers_size 64k;      # "busy" means Nginx received the entire response from PHP-FPM, but client yet to confirm received the entire response
                                        # Don't let a slow-receiving client consume lots of memory / temp disk space
                                        # While `fastcgi_busy_buffers_size` exceeded, Nginx stops reading from PHP-FPM; Risks triggering `fastcgi_read_timeout`
                                        # Default is 2 * fastcgi_buffer_size (i.e. 2 buffers)

    fastcgi_keep_conn on;               # Note: relevant for both TCP and socket connection

    # HTTP compression
    gzip off;

    # Cluster-internal traffic (e.g. health-checks, Nginx-exporter)
    server {
        listen 8081;
        listen [::]:8081;

        access_log off;

        keepalive_timeout 35s;      # Nginx-exporter: every 15 seconds  readinessProbe: every 30 seconds
        keepalive_requests 40320;   # Nginx-exporter: 1 week            readinessProbe: 2 weeks

        # Nginx health check
        location = /nginx-up {
            add_header Content-Type text/plain always;
            return 200 "up";
        }

        # Nginx Prometheus exporter
        location /nginx-status {
            stub_status;
        }

        # Laravel health checks and metrics
        location ~ ^/(php-fpm-status|php-fpm-ping|laravel-startup|laravel-readiness|laravel-status|laravel-metrics)$ {
            fastcgi_pass    unix:/var/run/php/php-fpm.sock;
            include         fastcgi_params;
            fastcgi_param   SCRIPT_FILENAME     /app/public/index.php;
            fastcgi_param   HTTP_PROXY "";
        }
    }

    # External traffic
    server {
        listen 8080;
        listen [::]:8080;

        root /usr/share/nginx/static;

        limit_conn conn_api 20;
        limit_req zone=req_api burst=20 nodelay;

        keepalive_timeout 30s;  # Max life of a keepalive connection
        keepalive_requests 100; # Max requests over a keepalive connection

        charset UTF-8;
        default_type application/json;
        add_header X-Content-Type-Options "nosniff" always; # Global header

        error_page 400 @400;    # Bad Request
        error_page 404 @404;    # Not Found
        error_page 405 @405;    # Method Not Allowed
        error_page 408 @408;    # Request Timeout
        error_page 413 @413;    # Payload Too Large (`client_max_body_size` exceeded)
        error_page 414 @414;    # URI Too Long
        error_page 429 @429;    # Too Many Requests
        error_page 401 402 403 406 407 409 410 411 412 415 415 417 418 419 420 421
                   422 423 424 425 426 428 429 430 431 440 444 449 450 451 460 463
                   464 494 495 496 497 498 @4xx;
        error_page 500 501 502 503 504 505 506 507 508 509 510 511 520 521 522 523
                   524 525 526 527 529 530 561 598 599 @5xx;

        location @400 { try_files /errors/400.json =400; }
        location @404 { try_files /errors/404.json =404; }
        location @405 { try_files /errors/405.json =405; }
        location @408 { try_files /errors/408.json =408; }
        location @413 { try_files /errors/413.json =413; }
        location @414 { try_files /errors/414.json =414; }
        location @429 { try_files /errors/429.json =429; }
        location @4xx { try_files /errors/4xx.json =400; }
        location @5xx { try_files /errors/5xx.json =500; }

        # No logs for favicon.ico / robots.txt
        location ~ ^/(favicon.ico|robots.txt)$ {
            access_log off;
            add_header X-Content-Type-Options "nosniff" always;                     # Global header
            add_header Cache-Control "public, max-age=31536000, immutable" always;  # Cache: 1 year immutable
        }

        # Dev only: Telescope
        include /etc/nginx/conf.d/8080/*.conf;

        # Only allow prefix: /api/v1
        # Also blocks internal routes: /php-fpm-status /php-fpm-ping /laravel-readiness
        location ~ ^(?!/api/v1/).+ {
            return 404;
        }

        # Laravel
        location / {
            # CORS preflight
            # if ($request_method = OPTIONS) {
            #     add_header Access-Control-Allow-Origin "https://wh-vue.ianf.dev" always;
            #     add_header Access-Control-Allow-Methods "GET, POST, PUT, PATCH, DELETE, OPTIONS" always;
            #     add_header Access-Control-Allow-Headers "Authorization, Content-Type, X-Requested-With" always;
            #     add_header Access-Control-Allow-Credentials "true" always;
            #     add_header Content-Length 0;
            #     add_header Content-Type text/plain;
            #     return 204;
            # }

            # Normal requests (GET, POST, etc.)
            add_header X-Content-Type-Options "nosniff" always;                     # Global header
            add_header X-Robots-Tag "noindex, nofollow" always;                     # API-specific header
            # Cache header set by Laravel

            fastcgi_pass    unix:/var/run/php/php-fpm.sock;
            include         fastcgi_params;
            fastcgi_param   SCRIPT_FILENAME     /app/public/index.php;
            fastcgi_param   HTTP_X_REQUEST_ID   $request_id_header;
            fastcgi_param   HTTP_PROXY          "";
        }
    }

    include /etc/nginx/conf.d/*.conf;
}
